# Contenedores para Dahell Intelligence (Scraper + DB + GUI)
version: '3.8'

services:
  # 1. Base de Datos (PostgreSQL 17 + pgvector)
  db:
    image: pgvector/pgvector:pg17
    container_name: dahell_db
    restart: always
    env_file:
      - .env.docker
    volumes:
      - pg_data:/var/lib/postgresql/data
      # Script de inicialización: Crea las tablas al arrancar la primera vez
      - ./docs/dahell_db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5433:5432"
    networks:
      - dahell_net

  # 2. Interfaz Gráfica para DB (pgAdmin 4)
  pgadmin:
    image: dpage/pgadmin4
    container_name: dahell_pgadmin
    restart: always
    env_file:
      - .env.docker
    ports:
      - "5050:80"
    depends_on:
      - db
    networks:
      - dahell_net

  # 3. Scraper (Python + Selenium)
  scraper:
    build:
      context: .
      target: selenium
    container_name: dahell_scraper
    # Comparte variables del .env con Python
    env_file:
      - .env.docker
    volumes:
      - ./raw_data:/app/raw_data # Persistir JSONs y fotos descargadas
      - ./backend:/app/backend # Código fuente actualizado
      - ./logs:/app/logs
    # Límites de recursos AUMENTADOS
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    shm_size: '1g' # Aumentado de 512m a 1 GB (Chrome necesita más)
    # No inicia solo, tú lo lanzas cuando quieras scrapear
    profiles: [ "workers" ]
    networks:
      - dahell_net
    # Comando por defecto (opcional, o se corre manual)
    command: python backend/manage.py scraper
    restart: on-failure:3 # Auto-reinicio en caso de error
    depends_on:
      - db

  loader:
    build:
      context: .
      target: selenium
    container_name: dahell_loader
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./raw_data:/app/raw_data
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 500M
    networks:
      - dahell_net
    command: python backend/manage.py loader
    profiles: [ "workers" ]
    restart: on-failure:3 # Auto-reinicio en caso de error
    depends_on:
      - db

  vectorizer:
    build:
      context: .
      target: vectorizer
    container_name: dahell_vectorizer
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./cache_huggingface:/app/cache_huggingface
      - ./logs:/app/logs
    # ⚡ Habilitar acceso a la GPU NVIDIA
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    networks:
      - dahell_net
    command: python backend/manage.py vectorizer
    profiles: [ "workers" ]
    restart: on-failure:3 # Auto-reinicio en caso de error
    depends_on:
      - db

  clusterizer:
    build:
      context: .
      target: selenium # Reusamos la imagen que ya tiene python y librerias
    container_name: dahell_clusterizer
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    networks:
      - dahell_net
    command: python backend/manage.py clusterizer
    profiles: [ "workers" ]
    restart: no
    depends_on:
      - db

  classifier:
    build:
      context: .
      target: selenium
    container_name: dahell_classifier
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1.2G
    networks:
      - dahell_net
    command: python backend/manage.py classifier
    profiles: [ "workers" ]
    restart: no
    depends_on:
      - db

  classifier_2:
    build:
      context: .
      target: selenium
    container_name: dahell_classifier_2
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1.2G
    networks:
      - dahell_net
    command: python backend/manage.py classifier
    profiles: [ "workers" ]
    restart: no
    depends_on:
      - db

  market_trender:
    build:
      context: .
      target: selenium
    container_name: dahell_market_trender
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    networks:
      - dahell_net
    command: python backend/manage.py market_trender
    profiles: [ "workers" ]
    restart: no
    depends_on:
      - db

  meta_scholar:
    build:
      context: .
      target: selenium
    container_name: dahell_meta_scholar
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./cache_huggingface:/app/cache_huggingface
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
    networks:
      - dahell_net
    command: python backend/manage.py meta_scholar
    profiles: [ "workers" ]
    restart: "no"
    depends_on:
      - db
      - backend

  shopify_auditor:
    build:
      context: .
      target: selenium
    container_name: dahell_shopify_auditor
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./raw_data:/app/raw_data
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    networks:
      - dahell_net
    command: python backend/manage.py shopify_auditor
    profiles: [ "workers" ]
    restart: no
    depends_on:
      - db

  # 5. Backend API (Django REST Framework)
  backend:
    build:
      context: .
      target: selenium
    container_name: dahell_backend
    restart: always
    env_file:
      - .env.docker
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./cache_huggingface:/app/cache_huggingface
      - /var/run/docker.sock:/var/run/docker.sock # Control Docker from within container
    ports:
      - "8000:8000"
    command: python backend/manage.py runserver 0.0.0.0:8000
    networks:
      - dahell_net
    depends_on:
      - db

  # 6. Frontend (React + Vite)
  frontend:
    image: node:20-alpine
    container_name: dahell_frontend
    restart: always
    working_dir: /app
    volumes:
      - ./frontend:/app
      - /app/node_modules # Evitar conflictos con node_modules del host
    ports:
      - "5173:5173"
    environment:
      - CHOKIDAR_USEPOLLING=true # Necesario para hot-reload en Windows/Docker
    command: sh -c "npm install && npm run dev -- --host"
    networks:
      - dahell_net

volumes:
  pg_data:
    # Persistencia de la DB

networks:
  dahell_net:
    driver: bridge
